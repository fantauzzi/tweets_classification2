hydra:
  run:
    dir: ../outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
main:
  models_dir: models #Relative to the root of the repo
  fine_tuned_model_dir: fine_tuned_model
wandb:
  project: tweets_classification_prj
  count: 10
mlflow:
  tracking_uri: mlruns # Relative to the root of the repo, currently only a local path is supported as uri
transformers:
  pretrained_model: distilbert-base-uncased
early_stopping:
  patience: 1
training:
  seed: 8833
  num_train_epochs: 10
  per_device_train_batch_size: 256
  per_device_eval_batch_size: 256
  learning_rate: 2e-5
  weight_decay: 0.01
  evaluation_strategy: epoch
  disable_tqdm: False
  push_to_hub: False
  log_level: error
  logging_strategy: epoch
  report_to:
    - wandb
  logging_first_step: False
  save_strategy: 'epoch'
test:
  model: # fine-tuned_model:v13
openai:
  # dataset_file: requests_for_GPT.jsonl
  results_file: test_prepared_results.jsonl
  # temperature: 0.0
  # model: text-ada-001
  fine_tuned_model: curie:ft-personal-2023-06-06-12-04-14
  # endpoint: https://api.openai.com/v1/completions
